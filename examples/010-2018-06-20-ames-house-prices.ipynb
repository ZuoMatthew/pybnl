{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Christian Schuhegger' -u -d -v -p numpy,xarray,scipy,pandas,sklearn,matplotlib,seaborn,qgrid,rpy2,libpgm,pgmpy,networkx,graphviz,pybnl,pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, xarray as xr, matplotlib.pyplot as plt, seaborn as sns\n",
    "import sklearn, sklearn.pipeline, sklearn.model_selection, sklearn.naive_bayes\n",
    "import networkx as nx, graphviz, networkx.algorithms.dag\n",
    "import random\n",
    "import itertools, collections\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.set_printoptions(suppress=True)\n",
    "np.core.arrayprint._line_width = 180\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        if type(df) == np.ndarray:\n",
    "            df = pd.DataFrame(df)\n",
    "        html_str+=df.to_html()\n",
    "    html_str = html_str.replace('table','table style=\"display:inline\"')\n",
    "    # print(html_str)\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def display_graphs_side_by_side(*args):\n",
    "    html_str='<table><tr>'\n",
    "    for g in args:\n",
    "        html_str += '<td>'\n",
    "        html_str += g._repr_svg_()\n",
    "        html_str += '</td>'\n",
    "    html_str += '</tr></table>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport pybnl.bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport dsbasics.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "import rpy2, rpy2.rinterface, rpy2.robjects, rpy2.robjects.packages, rpy2.robjects.lib, rpy2.robjects.lib.grid, \\\n",
    "    rpy2.robjects.lib.ggplot2, rpy2.robjects.pandas2ri, rpy2.interactive.process_revents, \\\n",
    "    rpy2.interactive, rpy2.robjects.lib.grdevices\n",
    "# rpy2.interactive.process_revents.start()\n",
    "rpy2.robjects.pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpackageversionfn = rpy2.robjects.r('packageVersion')\n",
    "print(rpackageversionfn(\"bnlearn\")[0])\n",
    "print(rpackageversionfn(\"gRain\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices in Ames, Iowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project](http://ww2.amstat.org/publications/jse/v19n3/decock.pdf)\n",
    "  * [AmesResidential.pdf](https://ww2.amstat.org/publications/jse/v19n3/decock/AmesResidential.pdf)\n",
    "  * [DataDocumentation.txt](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt)\n",
    "  * [AmesHousing.txt](https://ww2.amstat.org/publications/jse/v19n3/decock/AmesHousing.txt)\n",
    "  * [AmesHousing.xls](http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls)\n",
    "  * Also on [kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below example reproduces the example from chapter 5 (page 79) in [Bayesian Networks and BayesiaLab: A Practical Introduction for Researchers](https://www.amazon.com/Bayesian-Networks-BayesiaLab-Introduction-Researchers/dp/0996533303)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./AmesHousing.txt.gz', sep='\\t', index_col=0)\n",
    "df['MS SubClass'] = df['MS SubClass'].apply(lambda x: '{0:0>3}'.format(x))\n",
    "df.iloc[:5,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_non_null, discrete_with_null, continuous_non_null, continuous_with_null, levels_map = pybnl.bn.discrete_and_continuous_variables_with_and_without_nulls(df, cutoff=30)\n",
    "# discrete_non_null, discrete_with_null, continuous_non_null, continuous_with_null, levels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.copy()\n",
    "#cat_columns = ['Alley', 'Bedroom AbvGr', 'Bldg Type', 'Bsmt Cond', ]\n",
    "cat_columns = [\n",
    "    'MS SubClass', 'MS Zoning', 'Street', 'Alley', 'Land Contour', 'Lot Config', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style',\n",
    "    'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', 'Misc Feature', 'Sale Type', 'Sale Condition'\n",
    "] + [\n",
    "    'Overall Qual', 'Overall Cond'\n",
    "]\n",
    "cat_columns_ordinal = [\n",
    "    ('Lot Shape',      ['Reg','IR1','IR2','IR3']),\n",
    "    ('Utilities',      ['AllPub','NoSewr','NoSeWa','ELO']),\n",
    "    ('Land Slope',     ['Gtl', 'Mod', 'Sev']),\n",
    "    ('Exter Qual',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Exter Cond',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Bsmt Qual',      ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Bsmt Cond',      ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Bsmt Exposure',  ['Gd', 'Av', 'Mn', 'No', 'NA']),\n",
    "    ('BsmtFin Type 1', ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'NA']),\n",
    "    ('BsmtFin Type 2', ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'NA']),\n",
    "    ('Heating QC',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Electrical',     ['SBrkr', 'FuseA', 'FuseF', 'FuseP', 'Mix']),\n",
    "    ('Kitchen Qual',   ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Functional',     ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal']),\n",
    "    ('Fireplace Qu',   ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Garage Finish',  ['Fin', 'RFn', 'Unf', 'NA']),\n",
    "    ('Garage Qual',    ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Garage Cond',    ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Paved Drive',    ['Y', 'P', 'N']),\n",
    "    ('Pool QC',        ['Ex', 'Gd', 'TA', 'Fa', 'NA']),\n",
    "    ('Fence',          ['GdPrv', 'MnPrv', 'GdWo', 'MnWw', 'NA']),\n",
    "]\n",
    "\n",
    "continuous_columns = [\n",
    "    'Lot Frontage', 'Lot Area', 'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
    "    'Screen Porch', 'Pool Area', 'Misc Val', 'SalePrice'\n",
    "]\n",
    "discrete_columns = ['Year Built', 'Year Remod/Add', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Mo Sold', 'Yr Sold', 'Bedroom AbvGr', 'Kitchen AbvGr']# do not exist: 'Bedroom',  'Kitchen'\n",
    "\n",
    "for col in cat_columns:\n",
    "    levels = levels_map[col]\n",
    "    # print('col: {}'.format(col))\n",
    "    # if all([isinstance(level, (int, float)) for level in levels]):\n",
    "    if all([np.issubdtype(type(level), np.number) for level in levels]):\n",
    "        # print('int, float column: {}'.format(col))\n",
    "        levels = sorted(levels)\n",
    "        ddf[col] = df[col].astype(pd.api.types.CategoricalDtype(levels, ordered=True))\n",
    "    else:\n",
    "        ddf[col] = df[col].astype(pd.api.types.CategoricalDtype(levels, ordered=False))\n",
    "\n",
    "for col, levels in cat_columns_ordinal:\n",
    "    ddf[col] = df[col].astype(pd.api.types.CategoricalDtype(levels[::-1], ordered=True))\n",
    "\n",
    "for col in continuous_columns:\n",
    "    ddf[col] = df[col].astype(float)\n",
    "\n",
    "for col in discrete_columns:\n",
    "    if pd.isnull(df[col]).any():\n",
    "        ddf[col] = df[col].astype(float)\n",
    "    else:\n",
    "        ddf[col] = df[col].astype(int)\n",
    "    \n",
    "# col   = 'Alley'\n",
    "# ddf[col]\n",
    "# ddf[~pd.isnull(ddf[col])][col]\n",
    "# value = np.nan\n",
    "# ddf.loc[df[col]==value,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Working with Pandas: Fixing messy column names](https://medium.com/@chaimgluck1/working-with-pandas-fixing-messy-column-names-42a54a6659cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.columns = ddf.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf.to_hdf('AmesHousing.h5', 'AmesHousing',format='table', append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_hdf('AmesHousing.h5', 'AmesHousing').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating Filtered Values ('FV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See page 84 in \"Bayesian Networks and BayesiaLab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bsmt fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_fields_ = ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2', 'Bsmt Full Bath', 'Bsmt Half Bath', \n",
    "               'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF']\n",
    "bsmt_fields = pd.Index(bsmt_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf[bsmt_fields].query('Bsmt_Qual == \"NA\"')\n",
    "# ddf[ddf['Bsmt_Qual'] == 'NA'][bsmt_fields]\n",
    "# df[bsmt_fields_][df['Bsmt Qual'] == 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no filtered values for 'Bsmt' fields, e.g. each home contains a basement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Querying for NaN and other names in Pandas](https://stackoverflow.com/questions/26535563/querying-for-nan-and-other-names-in-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.Bsmt_Qual)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[bsmt_fields_][pd.isnull(df['Bsmt Qual'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are quite a lot of 'NaN' entries. Not sure why the data description contains an \"NA\" value as \"No Basement\", but no actual data-set uses it. Most likely these values are supposed to be \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.Bsmt_Qual) & ~pd.isnull(ddf.BsmtFin_Type_2)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_na_fields = ['Bsmt_Qual', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2']\n",
    "ddf.loc[pd.isnull(ddf.Bsmt_Qual), bsmt_na_fields] = \"NA\"\n",
    "ddf[bsmt_fields].query('Bsmt_Qual == \"NA\"').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrical field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.Electrical.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[pd.isnull(ddf.Electrical)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one NaN value seems to be a missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fireplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireplaces_fields_ = ['Fireplaces', 'Fireplace Qu']\n",
    "fireplaces_fields = pd.Index(fireplaces_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf[fireplaces_fields].query('Fireplaces == 0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[ddf.Fireplaces == 0,['Fireplace_Qu']] = 'NA'\n",
    "ddf[fireplaces_fields].query('Fireplaces == 0').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_fields_ = ['Garage Type', 'Garage Finish', 'Garage Cars', 'Garage Qual', 'Garage Cond', 'Garage Yr Blt', 'Garage Area']\n",
    "garage_fields = pd.Index(garage_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf[garage_fields][pd.isnull(ddf.Garage_Type)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['Garage_Type'] = ddf['Garage_Type'].astype(str)\\\n",
    "    .astype(pd.api.types.CategoricalDtype(set(list(ddf.Garage_Type.dtype.categories) + ['NA'])))\n",
    "ddf.Garage_Type.dtype.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Garage_Type),['Garage_Type', 'Garage_Finish', 'Garage_Qual', 'Garage_Cond']] = 'NA'\n",
    "ddf.loc[ddf.Garage_Type == 'NA',['Garage_Yr_Blt']] = -1.0\n",
    "#ddf[garage_fields][pd.isnull(ddf.Garage_Yr_Blt)]\n",
    "#ddf['Garage_Yr_Blt'] = ddf['Garage_Yr_Blt'].astype(int)\n",
    "ddf[garage_fields][ddf.Garage_Type == 'NA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mas Vnr fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_vnr_fields_ = ['Mas Vnr Type', 'Mas Vnr Area']\n",
    "mas_vnr_fields = pd.Index(mas_vnr_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf[mas_vnr_fields][pd.isnull(ddf.Mas_Vnr_Type)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[mas_vnr_fields][(ddf.Mas_Vnr_Type == 'None') & (ddf.Mas_Vnr_Area != 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.Mas_Vnr_Type.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Mas_Vnr_Type), ['Mas_Vnr_Type']] = 'None'\n",
    "# ddf.loc[ddf.Mas_Vnr_Type == 'None', ['Mas_Vnr_Area']] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Mas_Vnr_Area), ['Mas_Vnr_Area']] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf[mas_vnr_fields][ddf.Mas_Vnr_Type == 'None'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_fields_ = ['Pool QC', 'Pool Area']\n",
    "pool_fields = pd.Index(pool_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf[pool_fields][pd.isnull(ddf.Pool_QC)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Pool_QC), ['Pool_QC']] = 'NA'\n",
    "ddf[pool_fields][ddf.Pool_QC == 'NA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fence field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fence_fields_ = ['Fence']\n",
    "fence_fields = pd.Index(fence_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf.loc[pd.isnull(ddf.Fence), ['Fence']] = 'NA'\n",
    "ddf[fence_fields][ddf.Fence == 'NA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc Feature field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_feature_fields_ = ['Misc Feature']\n",
    "misc_feature_fields = pd.Index(misc_feature_fields_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "ddf['Misc_Feature'] = ddf['Misc_Feature'].astype(str)\\\n",
    "    .astype(pd.api.types.CategoricalDtype(set(list(ddf.Misc_Feature.dtype.categories) + ['NA'])))\n",
    "ddf.loc[pd.isnull(ddf.Misc_Feature), ['Misc_Feature']] = 'NA'\n",
    "ddf[misc_feature_fields][ddf.Misc_Feature == 'NA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check remaining nan fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, discrete_with_null_, _, continuous_with_null_, _ = pybnl.bn.discrete_and_continuous_variables_with_and_without_nulls(ddf, cutoff=30)\n",
    "discrete_with_null_, continuous_with_null_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.Bsmt_Exposure)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set the few NaN values to 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Bsmt_Exposure),['Bsmt_Exposure']] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.BsmtFin_Type_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set the few NaN values to 'Unf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.BsmtFin_Type_2),['BsmtFin_Type_2']] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.Bsmt_Full_Bath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[bsmt_fields][pd.isnull(ddf.Bsmt_Half_Bath)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set all the NaN values to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Bsmt_Full_Bath),['Bsmt_Full_Bath','Bsmt_Half_Bath','BsmtFin_SF_1','BsmtFin_SF_2','Bsmt_Unf_SF','Total_Bsmt_SF']] = [0.0,0.0,0.0,0.0,0.0,0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[['Electrical']][pd.isnull(ddf.Electrical)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set this single NaN value to 'Mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[pd.isnull(ddf.Electrical),['Electrical']] = 'Mix'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining NaN garage fields seem to be really missing values so don't touch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[garage_fields][pd.isnull(ddf.Garage_Finish)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[garage_fields][pd.isnull(ddf.Garage_Cars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[garage_fields][pd.isnull(ddf.Garage_Qual)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[garage_fields][pd.isnull(ddf.Garage_Cond)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lot_Frontage NaN fields seem to be really missing values so don't touch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf[pd.isnull(ddf.Lot_Frontage)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, discrete_with_null_, _, continuous_with_null_, _ = pybnl.bn.discrete_and_continuous_variables_with_and_without_nulls(ddf, cutoff=30)\n",
    "discrete_with_null_, continuous_with_null_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning / Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1 = ddf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The target variable is SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.SalePrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1.SalePrice = pd.cut(ddf.SalePrice, [0.0,75000.0, 150000.0, 225000.0, 300000.0,np.PINF], right=False)\n",
    "ddf1['SalePrice'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous, discrete and ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns_without_sale_price = list(set(continuous_columns) - set(['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable_decision_tree_binning_variables_ = [c for c,r in cat_columns_ordinal] + continuous_columns_without_sale_price + discrete_columns + ['Overall Qual', 'Overall Cond']\n",
    "target_variable_decision_tree_binning_variables = pd.Index(target_variable_decision_tree_binning_variables_).str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "target_variable_decision_tree_binning_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ddf_before_binning = ddf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvbt = dsbasics.bin.TargetVariableDecisionTreeBinTransformer0(max_leaf_nodes=3)\n",
    "ddf1.loc[:,target_variable_decision_tree_binning_variables] = \\\n",
    "    tvbt.fit_transform(ddf[target_variable_decision_tree_binning_variables], ddf1.SalePrice)\n",
    "ddf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns),len(ddf1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['Overall_Qual'].value_counts().sort_index().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1['Overall_Qual'].value_counts().sort_index().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert interval indices to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1 = pybnl.bn.convert_interval_index_categories_to_string_categories(ddf1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1.Bsmt_Full_Bath.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns to fit with R conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1 = ddf1.rename(columns={\n",
    "    \"1st_Flr_SF\":\"X1st_Flr_SF\",\n",
    "    \"2nd_Flr_SF\":\"X2nd_Flr_SF\",\n",
    "    \"3Ssn_Porch\":\"X3Ssn_Porch\",\n",
    "    \"Year_Remod/Add\":\"Year_Remod_Add\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(ddf1.columns.isin(['PID'])):\n",
    "    ddf1.drop('PID', axis=1, inplace=True)\n",
    "# ddf1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the 'Alley' column, which contains most null values and will not contribute to the quality of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if any(ddf1.columns.isin(['Alley'])):\n",
    "    ddf1.drop('Alley', axis=1, inplace=True)\n",
    "# ddf1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns with null values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, discrete_with_null_, _, continuous_with_null_, _ = pybnl.bn.discrete_and_continuous_variables_with_and_without_nulls(ddf1, cutoff=30)\n",
    "discrete_with_null_, continuous_with_null_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of the NaN values are as follows. Only the column `Lot_Frontage` still has relevant null values, e.g. we could simply filter out the 2 `Garage` rows that contain null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side(\n",
    "    pd.DataFrame(ddf1.Lot_Frontage.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Yr_Blt.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Finish.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Cars.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Area.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Qual.value_counts(dropna=False)),\n",
    "    pd.DataFrame(ddf1.Garage_Cond.value_counts(dropna=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_value_idx = pd.isnull(ddf1.Lot_Frontage) | pd.isnull(ddf1.Garage_Yr_Blt) | pd.isnull(ddf1.Garage_Finish) | \\\n",
    "    pd.isnull(ddf1.Garage_Cars) | pd.isnull(ddf1.Garage_Area) | pd.isnull(ddf1.Garage_Qual) | pd.isnull(ddf1.Garage_Cond)\n",
    "null_value_idx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_without_null_values = ddf1[~null_value_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_with_null_values = ddf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bnlearn by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = nx.DiGraph()\n",
    "\n",
    "dg.add_nodes_from(ddf1.columns.values)\n",
    "\n",
    "in_vars = ddf1.columns.values[:-1]\n",
    "out_var = ddf1.columns.values[-1:]\n",
    "dg.add_edges_from(list(itertools.product(out_var, in_vars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = pybnl.bn.digraph2netstruct(dg)\n",
    "# ns.dot()\n",
    "display(HTML(ns.dot()._repr_svg_()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbn1 = pybnl.bn.NetAndDataDiscreteBayesNetwork(ldf=ddf_without_null_values, dg=dg, predict_var='SalePrice')\n",
    "nbn1.fit();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20 # restricted to speed up runtime of notebook\n",
    "y_pred = nbn1.predict(ddf_without_null_values.iloc[:N,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = ddf_without_null_values.iloc[:N,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cm = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "tmp_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(tmp_cm).sum()/tmp_cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbn1.arc_strength_info().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbn1.arc_strength_info().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(nbn1.dot()._repr_svg_()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bnlearn via naive.bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn = pybnl.bn.MultinomialNB()\n",
    "mbn.fit(ddf_without_null_values[in_vars], ddf_without_null_values[out_var[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn.arc_strength_info().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(mbn.dot()._repr_svg_()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted vs. real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn_predict_df = pd.DataFrame([\n",
    "    mbn.predict(ddf_without_null_values[in_vars]),\n",
    "    ddf_without_null_values[out_var[0]].reset_index(drop=True),    \n",
    "])\n",
    "mbn_predict_df.columns = ['predicted', 'actual']\n",
    "mbn_predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn.predict_proba(ddf_without_null_values[in_vars]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted vs. real with probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mbn_predict_with_probabilities_df = pd.DataFrame([\n",
    "    mbn.predict(ddf_without_null_values[in_vars]),\n",
    "    mbn.predict_proba(ddf_without_null_values[in_vars]).max(axis=1).reset_index(drop=True),\n",
    "    ddf_without_null_values[out_var[0]].reset_index(drop=True),\n",
    "    mbn.predict_proba(\n",
    "        ddf_without_null_values[in_vars]\n",
    "    ).values[\n",
    "        np.array(range(len(ddf_without_null_values))).reshape(-1,1),\n",
    "        ddf_without_null_values[out_var[0]].values.codes.reshape(-1,1)\n",
    "    ].reshape(-1)\n",
    "])\n",
    "mbn_predict_with_probabilities_df.columns = ['predicted', 'predicted-probability', 'actual', 'actual-probability']\n",
    "mbn_predict_with_probabilities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label scores / how well do you get the labels right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(mbn_predict_df.actual, mbn_predict_df.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn_predict_cm = sklearn.metrics.confusion_matrix(mbn_predict_df.actual, mbn_predict_df.predicted)\n",
    "mbn_predict_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(mbn_predict_cm).sum()/mbn_predict_cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_score(mbn_predict_df.actual, mbn_predict_df.predicted, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.recall_score(mbn_predict_df.actual, mbn_predict_df.predicted, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.naive_bayes.MultinomialNB()\n",
    "X_ = ddf_without_null_values[in_vars]\n",
    "X  = X_.apply(lambda x: x.cat.codes, axis=0)\n",
    "y_ = ddf_without_null_values[out_var[0]]\n",
    "y  = y_.cat.codes\n",
    "clf.fit(X, y)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predict_with_probabilities_df = pd.DataFrame(\n",
    "    collections.OrderedDict([\n",
    "        ('predicted', pybnl.bn.from_codes_to_category(clf.predict(X),y_.dtype)),\n",
    "        ('predicted-probability', clf.predict_proba(X).max(axis=1)),\n",
    "        ('actual', y_.reset_index(drop=True)), \n",
    "        ('actual-probability', clf.predict_proba(X)[np.array(range(len(y))).reshape(-1,1),y.values.reshape(-1,1)].reshape(-1))\n",
    "    ])\n",
    ")\n",
    "clf_predict_with_probabilities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.dtype.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(clf_predict_with_probabilities_df.actual, clf_predict_with_probabilities_df.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertically: true label\n",
    "# horizontally: predicted label\n",
    "clf_predict_cm = sklearn.metrics.confusion_matrix(clf_predict_with_probabilities_df.actual, clf_predict_with_probabilities_df.predicted)\n",
    "clf_predict_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage of the SKLearnMultinomialNBWrapper to avoid the manual mapping between numbers and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ = pybnl.bn.SKLearnMultinomialNBWrapper()\n",
    "clf_.fit(ddf_without_null_values[in_vars], ddf_without_null_values[out_var[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_.predict(ddf_without_null_values[in_vars]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:5,:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn pipeline for data transformation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "# df_test.dsbmd = {}\n",
    "df_test.__dict__['dsbmd'] = {}\n",
    "df_test.dsbmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\n",
    "    'MS SubClass', 'MS Zoning', 'Street', 'Land Contour', 'Lot Config', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', #'Alley', \n",
    "    'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Heating', 'Central Air', 'Garage Type', 'Misc Feature', 'Sale Type', 'Sale Condition'\n",
    "] + [\n",
    "    'Overall Qual', 'Overall Cond'\n",
    "]\n",
    "cat_columns_ordinal = [\n",
    "    ('Lot Shape',      ['Reg','IR1','IR2','IR3']),\n",
    "    ('Utilities',      ['AllPub','NoSewr','NoSeWa','ELO']),\n",
    "    ('Land Slope',     ['Gtl', 'Mod', 'Sev']),\n",
    "    ('Exter Qual',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Exter Cond',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Bsmt Qual',      ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Bsmt Cond',      ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Bsmt Exposure',  ['Gd', 'Av', 'Mn', 'No', 'NA']),\n",
    "    ('BsmtFin Type 1', ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'NA']),\n",
    "    ('BsmtFin Type 2', ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf', 'NA']),\n",
    "    ('Heating QC',     ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Electrical',     ['SBrkr', 'FuseA', 'FuseF', 'FuseP', 'Mix']),\n",
    "    ('Kitchen Qual',   ['Ex', 'Gd', 'TA', 'Fa', 'Po']),\n",
    "    ('Functional',     ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Sal']),\n",
    "    ('Fireplace Qu',   ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Garage Finish',  ['Fin', 'RFn', 'Unf', 'NA']),\n",
    "    ('Garage Qual',    ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Garage Cond',    ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'NA']),\n",
    "    ('Paved Drive',    ['Y', 'P', 'N']),\n",
    "    ('Pool QC',        ['Ex', 'Gd', 'TA', 'Fa', 'NA']),\n",
    "    ('Fence',          ['GdPrv', 'MnPrv', 'GdWo', 'MnWw', 'NA']),\n",
    "]\n",
    "\n",
    "continuous_columns = [\n",
    "    'Lot Frontage', 'Lot Area', 'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
    "    'Screen Porch', 'Pool Area', 'Misc Val', 'SalePrice'\n",
    "]\n",
    "discrete_columns = ['Year Built', 'Year Remod/Add', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Mo Sold', 'Yr Sold', 'Bedroom AbvGr', 'Kitchen AbvGr']# do not exist: 'Bedroom',  'Kitchen'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns_NA = [\n",
    "    ('Misc Feature', ['Shed', 'Gar2', 'Othr', 'TenC', 'Elev', 'NA']),\n",
    "    ('Garage Type', ['Attchd', 'Detchd', 'BuiltIn', 'Basment', '2Types', 'CarPort', 'NA']),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Garage Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cat_columns_ordinal = [e for e,_ in cat_columns_ordinal]\n",
    "# tmp_cat_columns_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cat_columns_NA = [(e, 'NA') for e,_ in cat_columns_NA]\n",
    "tmp_cat_columns_NA += [('Bsmt Qual', 'NA'), ('Bsmt Cond', 'NA'), ('Bsmt Exposure', 'NA'), ('BsmtFin Type 1', 'NA'), ('BsmtFin Type 2', 'NA')] # \n",
    "tmp_cat_columns_NA += [('Fireplace Qu', 'NA')]\n",
    "tmp_cat_columns_NA += [('Garage Finish', 'NA'), ('Garage Qual', 'NA'), ('Garage Cond', 'NA'), ('Garage Yr Blt', -1.0)]\n",
    "tmp_cat_columns_NA += [('Mas Vnr Type', 'None'), ['Mas Vnr Area', 0.0]]\n",
    "tmp_cat_columns_NA += [('Pool QC', 'NA')]\n",
    "tmp_cat_columns_NA += [('Fence', 'NA')]\n",
    "tmp_cat_columns_NA += [('Misc Feature', 'NA')]\n",
    "tmp_cat_columns_NA += [('Bsmt Exposure', 'No'), ('BsmtFin Type 2', 'Unf'), ('Bsmt Full Bath', 0.0), ('Bsmt Half Bath', 0.0), ('BsmtFin SF 1', 0.0), ('BsmtFin SF 2', 0.0), ('Bsmt Unf SF', 0.0), ('Total Bsmt SF', 0.0)]\n",
    "tmp_cat_columns_NA += [('Electrical', 'Mix')]\n",
    "# tmp_cat_columns_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'{}'.format(sorted(['020', '060', '120', '050', '085', '160', '080', '030', '090', '190', '045', '070', '075', '040', '180', '150']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cat_columns_ordinal_1 = [(e, l[::-1]) for e,l in cat_columns_ordinal + cat_columns_NA]\n",
    "\n",
    "tmp_cat_columns_ordinal_1 += [\n",
    "    ('MS SubClass', ['020', '030', '040', '045', '050', '060', '070', '075', '080', '085', '090', '120', '150', '160', '180', '190']),\n",
    "    ('MS Zoning', ['RL', 'RH', 'FV', 'RM', 'C (all)', 'I (all)', 'A (agr)']), \n",
    "    ('Street', ['Pave', 'Grvl']),\n",
    "    ('Land Contour', ['Lvl', 'HLS', 'Bnk', 'Low']),\n",
    "    ('Lot Config', ['Corner', 'Inside', 'CulDSac', 'FR2', 'FR3']),\n",
    "    ('Neighborhood', ['NAmes', 'Gilbert', 'StoneBr', 'NWAmes', 'Somerst', 'BrDale', 'NPkVill', 'NridgHt', 'Blmngtn', 'NoRidge', 'SawyerW', 'Sawyer', 'Greens', 'BrkSide', 'OldTown', 'IDOTRR', 'ClearCr', 'SWISU', 'Edwards', 'CollgCr', 'Crawfor', 'Blueste', 'Mitchel', 'Timber', 'MeadowV', 'Veenker', 'GrnHill', 'Landmrk']),\n",
    "    ('Condition 1', ['Norm', 'Feedr', 'PosN', 'RRNe', 'RRAe', 'Artery', 'PosA', 'RRAn', 'RRNn']),\n",
    "    ('Condition 2', ['Norm', 'Feedr', 'PosA', 'PosN', 'Artery', 'RRNn', 'RRAe', 'RRAn']),\n",
    "    ('Bldg Type', ['1Fam', 'TwnhsE', 'Twnhs', 'Duplex', '2fmCon']),\n",
    "    ('House Style', ['1Story', '2Story', '1.5Fin', 'SFoyer', 'SLvl', '2.5Unf', '1.5Unf', '2.5Fin']),\n",
    "    ('Roof Style', ['Hip', 'Gable', 'Mansard', 'Gambrel', 'Shed', 'Flat']),\n",
    "    ('Roof Matl', ['CompShg', 'WdShake', 'Tar&Grv', 'WdShngl', 'Membran', 'ClyTile', 'Roll', 'Metal']),\n",
    "    ('Exterior 1st', ['BrkFace', 'VinylSd', 'Wd Sdng', 'CemntBd', 'HdBoard', 'Plywood', 'MetalSd', 'AsbShng', 'WdShing', 'Stucco', 'AsphShn', 'BrkComm', 'CBlock', 'PreCast', 'Stone', 'ImStucc']),\n",
    "    ('Exterior 2nd', ['Plywood', 'VinylSd', 'Wd Sdng', 'BrkFace', 'CmentBd', 'HdBoard', 'Wd Shng', 'MetalSd', 'ImStucc', 'Brk Cmn', 'AsbShng', 'Stucco', 'AsphShn', 'CBlock', 'Stone', 'PreCast', 'Other']),\n",
    "    ('Mas Vnr Type', ['Stone', 'None', 'BrkFace', 'BrkCmn', 'CBlock']),\n",
    "    ('Foundation', ['CBlock', 'PConc', 'Wood', 'BrkTil', 'Slab', 'Stone']),\n",
    "    ('Heating', ['GasA', 'GasW', 'Grav', 'Wall', 'Floor', 'OthW']),\n",
    "    ('Central Air', ['Y', 'N']),\n",
    "    ('Sale Type', ['WD ', 'New', 'COD', 'ConLI', 'Con', 'ConLD', 'Oth', 'ConLw', 'CWD', 'VWD']),\n",
    "    ('Sale Condition', ['Normal', 'Partial', 'Family', 'Abnorml', 'Alloca', 'AdjLand']),\n",
    "    ('Overall Qual', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
    "    ('Overall Cond', [1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
    "]\n",
    "\n",
    "tmp_levels_map = dict(tmp_cat_columns_ordinal_1)\n",
    "# tmp_levels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = dsbasics.bin.MetaDataInitTransformer()\n",
    "\n",
    "dc = dsbasics.bin.DropColumnTransformer(['PID', 'Alley'])\n",
    "\n",
    "ct = dsbasics.bin.CategoricalTransformer(\n",
    "    categorical_columns = cat_columns,\n",
    "    ordered_categorical_columns = tmp_cat_columns_ordinal, \n",
    "    discrete_columns = discrete_columns, \n",
    "    continuous_columns = continuous_columns, \n",
    "    levels_map = tmp_levels_map\n",
    ")\n",
    "\n",
    "nt = dsbasics.bin.NullToNATransformer(null_to_NA_columns = tmp_cat_columns_NA)\n",
    "\n",
    "pc = dsbasics.bin.PandasCutBinTransformer({'SalePrice': [75000.0, 150000.0, 225000.0, 300000.0]})\n",
    "\n",
    "tvbt = dsbasics.bin.TargetVariableDecisionTreeBinTransformer(\n",
    "    max_leaf_nodes=3, \n",
    "    binning_variables=target_variable_decision_tree_binning_variables_\n",
    ")\n",
    "\n",
    "lt = dsbasics.bin.CategoryLevelsAsStringsTransformer()\n",
    "\n",
    "fn = dsbasics.bin.FilterNullTransformer()\n",
    "\n",
    "pl = sklearn.pipeline.Pipeline(\n",
    "    memory=None,\n",
    "    steps=[\n",
    "        ('init', it),\n",
    "        ('drop_columns', dc),\n",
    "        ('ct', ct),\n",
    "        ('null_to_NA', nt),\n",
    "        ('target_variable_binning', pc),\n",
    "        ('decision_tree_discretization', tvbt),\n",
    "        ('levels_as_strings', lt),\n",
    "        ('filter_null_rows', fn),\n",
    "])\n",
    "\n",
    "tmp = pl.fit_transform(df.iloc[:,:-1], df.SalePrice)\n",
    "tmp.iloc[:5,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_without_null_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is due to record 1357 that we left in our hand example untouched (see above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tmp.index) - set(ddf_without_null_values.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other rows match perfectly, which you can check via the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm.tqdm(range(2438)):\n",
    "#     idx = ddf_without_null_values.index[i]\n",
    "#     row1 = ddf_without_null_values.iloc[:,:-1].loc[idx].reset_index(drop=True)\n",
    "#     row2 = tmp.loc[idx].reset_index(drop=True)\n",
    "#     if not row1.equals(row2):\n",
    "#         print(idx)\n",
    "#         break\n",
    "\n",
    "# eql=(row1==row2)\n",
    "# tmp_cmp = pd.DataFrame(collections.OrderedDict(nm=tmp.columns,row1=row1, row2=row2, eql=eql))\n",
    "# tmp_cmp[~tmp_cmp.eql]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['filter_null_rows'].null_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As SalePrice is not part of the X argument of the transform you can only look at the final outcome for this value via the internal state of the last transform step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.named_steps['levels_as_strings'].df.SalePrice.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also have a look at some of the other transformed fields like nominal, ordered and continous. The nominal stay untouched, because the tree regression binning is only working for ordered datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.Garage_Type.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.Garage_Type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp.Bsmt_Qual.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.Overall_Qual.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.Lot_Area.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn pipeline with bayes network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above data pipeline has element 1357 in addition to what we did above by hand. In order to generate comparable results let's drop this row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below \n",
    "df_ = df.copy()\n",
    "df_.drop(index=1357,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data pipeline predicts the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbnp = dsbasics.bin.MetaDataTransformerClassifierOrRegressorWrapper(pybnl.bn.MultinomialNB())\n",
    "\n",
    "it = dsbasics.bin.MetaDataInitTransformer()\n",
    "\n",
    "dc = dsbasics.bin.DropColumnTransformer(['PID', 'Alley'])\n",
    "\n",
    "ct = dsbasics.bin.CategoricalTransformer(\n",
    "    categorical_columns = cat_columns,\n",
    "    ordered_categorical_columns = tmp_cat_columns_ordinal, \n",
    "    discrete_columns = discrete_columns, \n",
    "    continuous_columns = continuous_columns, \n",
    "    levels_map = tmp_levels_map\n",
    ")\n",
    "\n",
    "nt = dsbasics.bin.NullToNATransformer(null_to_NA_columns = tmp_cat_columns_NA)\n",
    "\n",
    "pc = dsbasics.bin.PandasCutBinTransformer({'SalePrice': [75000.0, 150000.0, 225000.0, 300000.0]})\n",
    "\n",
    "tvbt = dsbasics.bin.TargetVariableDecisionTreeBinTransformer(\n",
    "    max_leaf_nodes=3, \n",
    "    binning_variables=target_variable_decision_tree_binning_variables_,\n",
    ")\n",
    "\n",
    "lt = dsbasics.bin.CategoryLevelsAsStringsTransformer()\n",
    "\n",
    "fn = dsbasics.bin.FilterNullTransformer()\n",
    "\n",
    "pl1 = sklearn.pipeline.Pipeline(\n",
    "    memory=None,\n",
    "    steps=[\n",
    "        ('init', it),\n",
    "        ('drop_columns', dc),\n",
    "        ('ct', ct),\n",
    "        ('null_to_NA', nt),\n",
    "        ('target_variable_binning', pc),\n",
    "        ('decision_tree_discretization', tvbt),\n",
    "        ('levels_as_strings', lt),\n",
    "        ('filter_null_rows', fn),\n",
    "        ('mbn', mbnp)\n",
    "])\n",
    "\n",
    "pl1.fit(df_.iloc[:,:-1], df_.SalePrice)\n",
    "pl1_pred_y = pl1.predict(df_.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1_actual_y = pl1.steps[-1][1].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `accuracy_score` gives as expected the exact same values as above with our manual case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(pl1_actual_y, pl1_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something like the below does not work in general, because the pipeline, by default, does not transform y-values for the real y-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl1.score(df_.iloc[:,:-1], df_.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to dataframes containing categories; they are tricky!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frames that contain categories store the type information per column. If you take in principle two data frames that contain the same string values but use different encodings you can get unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tmp_row1` is a row series of the data frame generated by the pipeline `pl2` as an intermediate step. As `tmp_row1` is a series it knows nothing about category datatypes and only stores strings. `tmp_row1_df` on the other hand is a dataframe and knows about categories and their encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row1    = pl1.steps[-1][1].df[in_vars].loc[1,:]\n",
    "tmp_row1_df = pl1.steps[-1][1].df[in_vars].loc[[1],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tmp_row2` and `tmp_row2_df` is the same for data generated above manually in `ddf_without_null_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row2    = ddf_without_null_values[in_vars].loc[1,:]\n",
    "tmp_row2_df = ddf_without_null_values[in_vars].loc[[1],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now put the rows (remember: they don't know anything about the categories) into a data-frame to compare the two we see no differences (the result is an empty data-frame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row_cmp = pd.DataFrame(collections.OrderedDict(l=tmp_row1, r=tmp_row2))\n",
    "tmp_row_cmp['dodiffer'] = tmp_row_cmp.l != tmp_row_cmp.r\n",
    "tmp_row_cmp[tmp_row_cmp.dodiffer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the data-frames by eye we also do not see any differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_row2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we would put them together into a single data-frame via `pd.concat` for example, we will get differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_columns = pybnl.bn.data_frame_data_type_diff(tmp_row1_df, tmp_row2_df)\n",
    "differences_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tmp_row1_df, tmp_row2_df])[differences_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would do the same in the inverse order we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tmp_row2_df, tmp_row1_df])[differences_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we can use above the `pl1.steps[-1][1].base_classifier` on the `ddf_without_null_values` data-frame, which is a category data-frame with a different encoding, is that internally the `predict` (and `predict_proba`) methods use `pybnl.bn.coerce_data_frame_types` function to ensure the correct encoding (by first converting the values to strings and then to a category data-type again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([tmp_row1_df, pybnl.bn.coerce_data_frame_types(tmp_row2_df,tmp_row1_df)])[differences_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([tmp_row2_df, pybnl.bn.coerce_data_frame_types(tmp_row1_df,tmp_row2_df)])[differences_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at what the best outcome would look like if we predict all labels right and how far our predicted value would differ from the real value.\n",
    "\n",
    "The real price is in `ddf_without_null_values_saleprice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_without_null_values_saleprice = ddf.loc[ddf_without_null_values.index]['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true labels are in `ddf_without_null_values['SalePrice']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we map each category to the median we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_saleprice_category_to_median_mapping = \\\n",
    "    ddf_without_null_values_saleprice.groupby(ddf_without_null_values['SalePrice']).median()\n",
    "# tmp_saleprice_category_to_median_mapping_dict = \\\n",
    "#     dict(zip(tmp_saleprice_category_to_median_mapping.index, tmp_saleprice_category_to_median_mapping.values))\n",
    "tmp_saleprice_category_to_median_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error introduced alone because of the discretization of the sale price even if you predict the \"label\" correctly is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_without_null_values_saleprice_reconstruct = ddf_without_null_values['SalePrice'].map(tmp_saleprice_category_to_median_mapping)\n",
    "minimum_reconstruction_error = \\\n",
    "    sklearn.metrics.median_absolute_error(ddf_without_null_values_saleprice, ddf_without_null_values_saleprice_reconstruct)\n",
    "minimum_reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed values for our `mbn` model that we created by hand are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn_pred_y = pd.Series(mbn.predict(ddf_without_null_values[in_vars])).map(tmp_saleprice_category_to_median_mapping)\n",
    "mbn_pred_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the resulting error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mbn_reconstruction_error = sklearn.metrics.median_absolute_error(ddf_without_null_values_saleprice, mbn_pred_y)\n",
    "mbn_reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest part of this error is coming from the binning/discretization. Only a small part of the error is coming from our model predicting the wrong label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mbn_reconstruction_error - minimum_reconstruction_error)/minimum_reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other metrics to look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other metrics to quantify the error, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sklearn.metrics.mean_squared_error(ddf_without_null_values_saleprice, mbn_pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.mean_absolute_error(ddf_without_null_values_saleprice, mbn_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What is the difference between the R2 and the explained variance score in Scikit-learn?](https://stats.stackexchange.com/questions/210168/what-is-the-difference-between-r2-and-variance-score-in-scikit-learn)\n",
    "* [explained-variance-score](http://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score)\n",
    "* [r2-score](http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.explained_variance_score(ddf_without_null_values_saleprice, mbn_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(ddf_without_null_values_saleprice, mbn_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn end-to-end pipeline with predicted y values (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the next one predicts the y-values via the mechanism we saw above where we map the labels to the medians for the training values falling into that label-category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbny = dsbasics.bin.ClassifierToRegressorHelper(pybnl.bn.MultinomialNB())\n",
    "\n",
    "it = dsbasics.bin.MetaDataInitTransformer()\n",
    "\n",
    "dc = dsbasics.bin.DropColumnTransformer(['PID', 'Alley'])\n",
    "\n",
    "ct = dsbasics.bin.CategoricalTransformer(\n",
    "    categorical_columns = cat_columns,\n",
    "    ordered_categorical_columns = tmp_cat_columns_ordinal, \n",
    "    discrete_columns = discrete_columns, \n",
    "    continuous_columns = continuous_columns, \n",
    "    levels_map = tmp_levels_map\n",
    ")\n",
    "\n",
    "nt = dsbasics.bin.NullToNATransformer(null_to_NA_columns = tmp_cat_columns_NA)\n",
    "\n",
    "pc = dsbasics.bin.PandasCutBinTransformer({'SalePrice': [75000.0, 150000.0, 225000.0, 300000.0]})\n",
    "\n",
    "tvbt = dsbasics.bin.TargetVariableDecisionTreeBinTransformer(\n",
    "    max_leaf_nodes=3, \n",
    "    binning_variables=target_variable_decision_tree_binning_variables_\n",
    ")\n",
    "\n",
    "lt = dsbasics.bin.CategoryLevelsAsStringsTransformer()\n",
    "\n",
    "fn = dsbasics.bin.FilterNullTransformer()\n",
    "\n",
    "pl2 = sklearn.pipeline.Pipeline(\n",
    "    memory=None,\n",
    "    steps=[\n",
    "        ('init', it),\n",
    "        ('drop_columns', dc),\n",
    "        ('ct', ct),\n",
    "        ('null_to_NA', nt),\n",
    "        ('target_variable_binning', pc),\n",
    "        ('decision_tree_discretization', tvbt),\n",
    "        ('levels_as_strings', lt),\n",
    "        ('filter_null_rows', fn),\n",
    "        ('mbny', mbny)\n",
    "])\n",
    "\n",
    "pl2.fit(df_.iloc[:,:-1], df_.SalePrice)\n",
    "pl2_pred_y = pl2.predict(df_.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is now doing the same as we did above manually as a sequence of transformations and the results match (as you will be able to see below). First let's look at the predicted results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2_pred_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's verify that the length of both predicted sequences is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pl2_pred_y), len(mbn_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's compare the predicted values generated by hand above in `mbn_pred_y` and the predicted values generated by `pl2` in `pl2_pred_y`. In order to do that we first have to make sure that the index values of `mbn_pred_y` match the data-frame indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbn_pred_y.index = ddf_without_null_values.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cmp_data_frame(ldf1_pred_y, ldf2_pred_y):\n",
    "    if not (ldf1_pred_y.index == ldf2_pred_y.index).all():\n",
    "        raise RuntimeError('Indices of the two data frames do not match! {}'.format(dsbasics.bin.index_compare(ldf1_pred_y, ldf2_pred_y)))\n",
    "    ldf_cmp = pd.DataFrame(collections.OrderedDict(df1=ldf1_pred_y, df2=ldf2_pred_y), index=ldf1_pred_y.index)\n",
    "    ldf_cmp['delta'] = np.abs(ldf_cmp.df1 - ldf_cmp.df2)\n",
    "    return ldf_cmp\n",
    "tmp_df_cmp = generate_cmp_data_frame(mbn_pred_y, pl2_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see there are 0 differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_cmp.delta.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df_cmp.sort_values(['delta'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a few score methods. First the `r2_score` integrated into the predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl2.score(df_.iloc[:,:-1], df_.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate this by hand. First we need to sub-select the real values from the input for which we have predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2_without_null_values_saleprice = df_.iloc[:,-1].loc[pl2_pred_y.index]\n",
    "# pl2_without_null_values_saleprice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can call the scoring function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(pl2_without_null_values_saleprice, pl2_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use other scoring functions of course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.median_absolute_error(pl2_without_null_values_saleprice, pl2_pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not make an awful lot of sense for a regressor, but we can also look at the label probabilities as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2.steps[-1][1].base_classifier.predict_proba(ddf_without_null_values[in_vars].loc[[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the data-frame of the last transform sequence step used during fitting via: `pl2.steps[-1][1].df` and repeat the call above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2.steps[-1][1].base_classifier.predict_proba(pl2.steps[-1][1].df[in_vars].loc[[1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn end-to-end pipeline with predicted y values (regression) with the sklearn.naive_bayes.MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_mnby = dsbasics.bin.ClassifierToRegressorHelper(pybnl.bn.SKLearnMultinomialNBWrapper())\n",
    "\n",
    "it = dsbasics.bin.MetaDataInitTransformer()\n",
    "\n",
    "dc = dsbasics.bin.DropColumnTransformer(['PID', 'Alley'])\n",
    "\n",
    "ct = dsbasics.bin.CategoricalTransformer(\n",
    "    categorical_columns = cat_columns,\n",
    "    ordered_categorical_columns = tmp_cat_columns_ordinal, \n",
    "    discrete_columns = discrete_columns, \n",
    "    continuous_columns = continuous_columns, \n",
    "    levels_map = tmp_levels_map\n",
    ")\n",
    "\n",
    "nt = dsbasics.bin.NullToNATransformer(null_to_NA_columns = tmp_cat_columns_NA)\n",
    "\n",
    "pc = dsbasics.bin.PandasCutBinTransformer({'SalePrice': [75000.0, 150000.0, 225000.0, 300000.0]})\n",
    "\n",
    "tvbt = dsbasics.bin.TargetVariableDecisionTreeBinTransformer(\n",
    "    max_leaf_nodes=3, \n",
    "    binning_variables=target_variable_decision_tree_binning_variables_\n",
    ")\n",
    "\n",
    "lt = dsbasics.bin.CategoryLevelsAsStringsTransformer()\n",
    "\n",
    "fn = dsbasics.bin.FilterNullTransformer()\n",
    "\n",
    "pl3 = sklearn.pipeline.Pipeline(\n",
    "    memory=None,\n",
    "    steps=[\n",
    "        ('init', it),\n",
    "        ('drop_columns', dc),\n",
    "        ('ct', ct),\n",
    "        ('null_to_NA', nt),\n",
    "        ('target_variable_binning', pc),\n",
    "        ('decision_tree_discretization', tvbt),\n",
    "        ('levels_as_strings', lt),\n",
    "        ('filter_null_rows', fn),\n",
    "        ('skl_mnby', skl_mnby)\n",
    "])\n",
    "\n",
    "pl3.fit(df_.iloc[:,:-1], df_.SalePrice)\n",
    "pl3_pred_y = pl2.predict(df_.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl3.score(df_.iloc[:,:-1], df_.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tutorial on MultinomialNB](http://universityofbigdata.net/competition/tutorial/5681717746597888?lang=en)\n",
    "* [Vectorization, Multinomial Naive Bayes Classifier and Evaluation](https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/)\n",
    "* [Computing cross-validated metrics](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "* [scoring-parameter](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have looked at scores evaluating our model against the training data itself. A model can always fit the training data perfectly but then fail at predicting unseen values. This is where [cross validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) comes in. You train the model on a certain sub-set of the overall data and you evaluate its predictions on the not seen data.\n",
    "\n",
    "Below we validate our model via [10-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_val_score(clf, X, y, cv=sklearn.model_selection.ShuffleSplit(n_splits=10, random_state=0)):\n",
    "    scores = pd.DataFrame(columns=['median_absolute_error', 'r2'])\n",
    "\n",
    "    i = 0\n",
    "    for train, test in tqdm.tqdm(list(cv.split(X,y))):\n",
    "        X_train = X.iloc[train,:]\n",
    "        y_train = y.iloc[train]\n",
    "        X_test = X.iloc[test,:]\n",
    "        y_test = y.iloc[test]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        tmp_pred_y = clf.predict(X_test)\n",
    "        y_test = y_test.loc[tmp_pred_y.index]\n",
    "        mae_score = sklearn.metrics.median_absolute_error(y_test, tmp_pred_y)\n",
    "        r2_score  = sklearn.metrics.r2_score(y_test, tmp_pred_y)\n",
    "        \n",
    "        scores.loc[i] = [mae_score, r2_score]\n",
    "        i += 1\n",
    "    \n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y      = df_.iloc[:,:-1], df_.SalePrice\n",
    "# scores_pl2 = my_cross_val_score(pl2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_pl2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_pl3 = my_cross_val_score(pl3, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores_pl3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the [bnlearn implementation](http://www.bnlearn.com/documentation/man/naive.bayes.html) of Naive Bayes performs better than the  [sklearn implementation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html). This matches our observations from above where we've seen that the scores for the bnlearn implementation when training and evaluating on the full data are better than the sklearn ones.\n",
    "\n",
    "I still do not understand why, because my expectations would be that Naive Bayes is a standard algorithm and different implementations should just match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_learning_curve(clf, X, y, train_sizes=np.array([ 0.1, 0.33, 0.55, 0.78, 1. ])):\n",
    "    cv_score_sequence = pd.DataFrame(columns=['median_absolute_error', 'r2'])\n",
    "    train_score_sequence = pd.DataFrame(columns=['median_absolute_error', 'r2'])\n",
    "    for ts in train_sizes:\n",
    "        if ts == 1.:\n",
    "            X_ = X.copy()\n",
    "            y_ = y.copy()\n",
    "        else:\n",
    "            _, X_, _, y_ = sklearn.model_selection.train_test_split(X, y, test_size=ts, random_state=42)\n",
    "\n",
    "        cv_scores = my_cross_val_score(clf, X_, y_, cv=sklearn.model_selection.ShuffleSplit(n_splits=3, random_state=42)).mean()\n",
    "        cv_score_sequence.loc[ts] = cv_scores\n",
    "        \n",
    "        clf.fit(X_,y_)\n",
    "        clf_predict_y = clf.predict(X_)\n",
    "        y_subselect = y_.loc[clf_predict_y.index]\n",
    "        clf_train_r2  = sklearn.metrics.r2_score(y_subselect, clf_predict_y)\n",
    "        clf_train_mae = sklearn.metrics.median_absolute_error(y_subselect, clf_predict_y)\n",
    "        train_score_sequence.loc[ts] = [clf_train_mae, clf_train_r2]\n",
    "    \n",
    "    score_sequence = pd.concat([train_score_sequence, cv_score_sequence],axis=1)\n",
    "    score_sequence.columns =  ['train_median_absolute_error', 'train_r2', 'cv_median_absolute_error', 'cv_r2']\n",
    "    return score_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl3_learning_curve_df = my_learning_curve(pl3, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl3_learning_curve_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[UserWarning about columns and attribute while plotting in Jupyter](https://github.com/pandas-dev/pandas/issues/18671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  [UserWarning about columns and attribute while plotting in Jupyter](https://github.com/pandas-dev/pandas/issues/18671)\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "#     pl3_learning_curve_df.plot(y=['train_r2', 'cv_r2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree / Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_X = df.loc[:,['Lot Area']]\n",
    "# rf_X = df.loc[:,continuous_columns]\n",
    "rf_y = df.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = sklearn.ensemble.RandomForestClassifier(n_estimators=10)\n",
    "rf_clf.fit(rf_X, rf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_y = rf_clf.predict(rf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(rf_y, rf_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.median_absolute_error(rf_y, rf_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_cv_mae_scores = \\\n",
    "#     sklearn.model_selection.cross_val_score(rf_clf, rf_X, rf_y, cv=sklearn.model_selection.ShuffleSplit(n_splits=10, random_state=0), \n",
    "#                                             scoring='neg_median_absolute_error')\n",
    "# rf_cv_r2_scores = \\\n",
    "#     sklearn.model_selection.cross_val_score(rf_clf, rf_X, rf_y, cv=sklearn.model_selection.ShuffleSplit(n_splits=10, random_state=0), \n",
    "#                                             scoring='r2')\n",
    "\n",
    "scoring = {'r2': 'r2',\n",
    "           'neg_median_absolute_error': 'neg_median_absolute_error'\n",
    "          }\n",
    "scores = sklearn.model_selection.cross_validate(rf_clf, rf_X, rf_y, scoring=scoring, \n",
    "                                                cv=sklearn.model_selection.ShuffleSplit(n_splits=10, random_state=0), \n",
    "                                                return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_df0 = pd.DataFrame(scores)\n",
    "# rf_scores_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores_df = pd.DataFrame()\n",
    "rf_scores_df['test_median_absolute_error'] = -rf_scores_df0['test_neg_median_absolute_error']\n",
    "rf_scores_df['train_median_absolute_error'] = -rf_scores_df0['train_neg_median_absolute_error']\n",
    "rf_scores_df['test_r2'] = rf_scores_df0['test_r2']\n",
    "rf_scores_df['train_r2'] = rf_scores_df0['train_r2']\n",
    "rf_scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
